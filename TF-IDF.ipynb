{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用gensim来计算TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'the', 'weather', 'like', 'today'], ['what', 'is', 'for', 'dinner', 'tonight'], ['this', 'is', 'a', 'question', 'worth', 'pondering'], ['it', 'is', 'a', 'beautiful', 'day', 'today']]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "from gensim import models\n",
    "# 建立一个语料库\n",
    "corpus = [\n",
    "    \"what is the weather like today\",\n",
    "    \"what is for dinner tonight\",\n",
    "    \"this is a question worth pondering\",\n",
    "    \"it is a beautiful day today\"\n",
    "]\n",
    "\n",
    "#进行分词\n",
    "words = []\n",
    "for i in corpus:\n",
    "    words.append(i.split(\" \"))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)], [(0, 1), (5, 1), (6, 1), (7, 1), (8, 1)], [(0, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)], [(0, 1), (3, 1), (9, 1), (14, 1), (15, 1), (16, 1)]]\n",
      "{'is': 0, 'like': 1, 'the': 2, 'today': 3, 'weather': 4, 'what': 5, 'dinner': 6, 'for': 7, 'tonight': 8, 'a': 9, 'pondering': 10, 'question': 11, 'this': 12, 'worth': 13, 'beautiful': 14, 'day': 15, 'it': 16}\n"
     ]
    }
   ],
   "source": [
    "#给每一个词一个ID并统计每个词在当前文档中出现的次数\n",
    "\"\"\"\n",
    "doc2bow函数主要用于让dic中的内用变为bow词袋模型，\n",
    "其中每个括号中的第一个数代表词的ID第二个数代表在当前文档中出现的次数。\n",
    "\"\"\"\n",
    "dic = corpora.Dictionary(words)\n",
    "new_corpus = [dic.doc2bow(text) for text in words]\n",
    "print(new_corpus)\n",
    "print(dic.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.5547001962252291), (2, 0.5547001962252291), (3, 0.2773500981126146), (4, 0.5547001962252291)]\n"
     ]
    }
   ],
   "source": [
    "#训练模型并保存\n",
    "tfidf = models.TfidfModel(new_corpus)\n",
    "tfidf.save(\"my_model.tfidf\")\n",
    "\n",
    "#载入模型\n",
    "tfidf = models.TfidfModel.load(\"my_model.tfidf\")\n",
    "\n",
    "#使用训练好的模型计算TF-IDF值\n",
    "string = \"i like the weather today\"\n",
    "string_bow = dic.doc2bow(string.lower().split())\n",
    "string_tfidf = tfidf[string_bow]\n",
    "print(string_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn来计算TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrix:\n",
      "   (0, 11)\t0.3710221459250386\n",
      "  (0, 6)\t0.47059454669821993\n",
      "  (0, 13)\t0.47059454669821993\n",
      "  (0, 9)\t0.47059454669821993\n",
      "  (0, 4)\t0.24557575678403082\n",
      "  (0, 14)\t0.3710221459250386\n",
      "  (1, 12)\t0.506765426545092\n",
      "  (1, 2)\t0.506765426545092\n",
      "  (1, 3)\t0.506765426545092\n",
      "  (1, 4)\t0.2644512224141842\n",
      "  (1, 14)\t0.3995396830595886\n",
      "  (2, 7)\t0.4838025881780501\n",
      "  (2, 15)\t0.4838025881780501\n",
      "  (2, 8)\t0.4838025881780501\n",
      "  (2, 10)\t0.4838025881780501\n",
      "  (2, 4)\t0.25246826075544676\n",
      "  (3, 1)\t0.506765426545092\n",
      "  (3, 0)\t0.506765426545092\n",
      "  (3, 5)\t0.506765426545092\n",
      "  (3, 11)\t0.3995396830595886\n",
      "  (3, 4)\t0.2644512224141842\n",
      "{'what': 14, 'is': 4, 'the': 9, 'weather': 13, 'like': 6, 'today': 11, 'for': 3, 'dinner': 2, 'tonight': 12, 'this': 10, 'question': 8, 'worth': 15, 'pondering': 7, 'it': 5, 'beautiful': 0, 'day': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    \"what is the weather like today\",\n",
    "    \"what is for dinner tonight\",\n",
    "    \"this is a question worth pondering\",\n",
    "    \"it is a beautiful day today\"\n",
    "]\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "#利用fit_transform得到TF-IDF矩阵\n",
    "tfidf_matrix = tfidf_vec.fit_transform(corpus)\n",
    "print(\"tfidf_matrix:\\n\",tfidf_matrix)\n",
    "\n",
    "#利用get_feature_names得到不重复的单词\n",
    "print(tfidf_vec.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手动实现TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'what': 1, 'is': 1, 'the': 1, 'weather': 1, 'like': 1, 'today': 1}, {'what': 1, 'is': 1, 'for': 1, 'dinner': 1, 'tonight': 1}, {'this': 1, 'is': 1, 'a': 1, 'question': 1, 'worth': 1, 'pondering': 1}, {'it': 1, 'is': 1, 'a': 1, 'beautiful': 1, 'day': 1, 'today': 1}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    " \n",
    "corpus = [\n",
    "    \"what is the weather like today\",\n",
    "    \"what is for dinner tonight\",\n",
    "    \"this is a question worth pondering\",\n",
    "    \"it is a beautiful day today\"\n",
    "]\n",
    "words = []\n",
    "# 对corpus分词\n",
    "for i in corpus:\n",
    "    words.append(i.split())\n",
    "\n",
    "#可以先取出停用词\n",
    "\n",
    "#进行词频统计\n",
    "def Counter(word_list):\n",
    "    wordcount = []\n",
    "    for i in word_list:\n",
    "        count = {}\n",
    "        for j in i:\n",
    "            if not count.get(j):\n",
    "                count.update({j:1})\n",
    "            elif count.get(j):\n",
    "                count[j] += 1\n",
    "        wordcount.append(count)\n",
    "    return wordcount\n",
    "\n",
    "wordcount = Counter(words)\n",
    "print(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what', 'is', 'the', 'weather', 'like', 'today'],\n",
       " ['what', 'is', 'for', 'dinner', 'tonight'],\n",
       " ['this', 'is', 'a', 'question', 'worth', 'pondering'],\n",
       " ['it', 'is', 'a', 'beautiful', 'day', 'today']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-dc1626cdca47>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-68-dc1626cdca47>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    return word_list.get(word) / 23) #这儿应该是总的词数\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#计算TF (word代表被计算的单词，word_list是被计算单词所在文档分词后的字典)\n",
    "def tf(word, word_list):\n",
    "    return word_list.get(word) / 23) #这儿应该是总的词数\n",
    "\n",
    "#统计含有该单词的句子数\n",
    "def count_sentence(word, wordcount):\n",
    "    return sum(1 for i in wordcount if i.get(word))\n",
    "\n",
    "#计算IDF\n",
    "def idf(word, wordcount):\n",
    "#     print('len(wordcount):',len(wordcount))\n",
    "#     print(\"(count_sentence(word , wordcount)):\",(count_sentence(word , wordcount)))\n",
    "#     print(\"log:\",math.log(len(wordcount) / (count_sentence(word , wordcount))))\n",
    "    return math.log(len(wordcount) / (count_sentence(word , wordcount)))\n",
    "\n",
    "#计算TF-IDF\n",
    "def tfidf(word, word_list, wordcount):\n",
    "    return tf(word, word_list) * idf(word, wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "for i in wordcount:\n",
    "    for j,k in i.items():\n",
    "        print(tf(j, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 2\n",
      "log: 0.6931471805599453\n",
      "0.6931471805599453\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 4\n",
      "log: 0.0\n",
      "0.0\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 2\n",
      "log: 0.6931471805599453\n",
      "0.6931471805599453\n",
      "\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 2\n",
      "log: 0.6931471805599453\n",
      "0.6931471805599453\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 4\n",
      "log: 0.0\n",
      "0.0\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 4\n",
      "log: 0.0\n",
      "0.0\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 2\n",
      "log: 0.6931471805599453\n",
      "0.6931471805599453\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 4\n",
      "log: 0.0\n",
      "0.0\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 2\n",
      "log: 0.6931471805599453\n",
      "0.6931471805599453\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 1\n",
      "log: 1.3862943611198906\n",
      "1.3862943611198906\n",
      "len(wordcount): 4\n",
      "(count_sentence(word , wordcount)): 2\n",
      "log: 0.6931471805599453\n",
      "0.6931471805599453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in wordcount:\n",
    "    for j,k in i.items():\n",
    "        print(idf(j, wordcount))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part:1\n",
      "word: what ---- TF-IDF:0.11552453009332421\n",
      "word: is ---- TF-IDF:0.0\n",
      "word: the ---- TF-IDF:0.23104906018664842\n",
      "word: weather ---- TF-IDF:0.23104906018664842\n",
      "word: like ---- TF-IDF:0.23104906018664842\n",
      "word: today ---- TF-IDF:0.11552453009332421\n",
      "part:2\n",
      "word: what ---- TF-IDF:0.13862943611198905\n",
      "word: is ---- TF-IDF:0.0\n",
      "word: for ---- TF-IDF:0.2772588722239781\n",
      "word: dinner ---- TF-IDF:0.2772588722239781\n",
      "word: tonight ---- TF-IDF:0.2772588722239781\n",
      "part:3\n",
      "word: this ---- TF-IDF:0.23104906018664842\n",
      "word: is ---- TF-IDF:0.0\n",
      "word: a ---- TF-IDF:0.11552453009332421\n",
      "word: question ---- TF-IDF:0.23104906018664842\n",
      "word: worth ---- TF-IDF:0.23104906018664842\n",
      "word: pondering ---- TF-IDF:0.23104906018664842\n",
      "part:4\n",
      "word: it ---- TF-IDF:0.23104906018664842\n",
      "word: is ---- TF-IDF:0.0\n",
      "word: a ---- TF-IDF:0.11552453009332421\n",
      "word: beautiful ---- TF-IDF:0.23104906018664842\n",
      "word: day ---- TF-IDF:0.23104906018664842\n",
      "word: today ---- TF-IDF:0.11552453009332421\n"
     ]
    }
   ],
   "source": [
    "p = 1\n",
    "for i in wordcount:\n",
    "    print(\"part:{}\".format(p))\n",
    "    p = p+1\n",
    "    for j,k in i.items():\n",
    "        print(\"word: {} ---- TF-IDF:{}\".format(j, tfidf(j, i, wordcount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what 1\n",
      "is 1\n",
      "the 1\n",
      "weather 1\n",
      "like 1\n",
      "today 1\n",
      "what 1\n",
      "is 1\n",
      "for 1\n",
      "dinner 1\n",
      "tonight 1\n",
      "this 1\n",
      "is 1\n",
      "a 1\n",
      "question 1\n",
      "worth 1\n",
      "pondering 1\n",
      "it 1\n",
      "is 1\n",
      "a 1\n",
      "beautiful 1\n",
      "day 1\n",
      "today 1\n"
     ]
    }
   ],
   "source": [
    "for i in wordcount:\n",
    "    for j,k in i.items():\n",
    "        print(j,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
